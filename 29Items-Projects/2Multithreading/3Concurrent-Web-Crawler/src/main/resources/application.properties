# Concurrent Web Crawler Configuration

# Thread Pool Settings
crawler.threads=10
crawler.maxConnections=20

# Crawl Behavior
crawler.maxPages=10000
crawler.maxDepth=10
crawler.defaultDelayMs=1000
crawler.requestTimeoutMs=30000

# User Agent
crawler.userAgent=ConcurrentCrawler/1.0 (+https://github.com/example/crawler)

# Robots.txt
crawler.respectRobotsTxt=true
crawler.robotsTxtCacheTtlMs=86400000

# Retry Settings
crawler.maxRetries=3
crawler.retryBaseDelayMs=1000

# Database
db.path=./data/crawler.db

# Domain Restrictions (comma-separated, leave empty for no restrictions)
crawler.allowedDomains=
crawler.blockedDomains=

# Logging
logging.level.root=INFO
logging.level.com.crawler=DEBUG
